# Welcome to the Tutorial on Deep Learning for Human Activity Recognition

This is the offical GitHub page of the tutorial "Deep Learning for Human Activity Recognition" first presented at the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp’21)/ International Symposium on Wearable Computers 21' (ISWC 21'). If you are interested in going through the whole tutorial please visit our GitHub page.

## Abstract
Physical activities play a crucial role in the way we structure our lives. Which activity, and how it is performed, can reveal a person’s intention, habit, fitness, and state of mind; it is therefore not surprising that a range of research fields, from cognitive science to healthcare, display a growing interest in the machine recognition of human activities. In 2014, Bulling et al. designed and organized an exceptionally well-received tutorial on human activity recognition from wearable sensor data. They introduced concepts such as the Activity Recognition Chain (ARC), a framework for designing and evaluating activity recognition systems, as well as a case study demonstrating how to work with this ARC. Within the last decade, deep learning methods have shown to outperform classical Machine Learning algorithms. We argue that releasing an updated tutorial that is adapted to work with deep learning techniques is long overdue. This tutorial introduces the Deep Learning Activity Recognition Chain (DL-ARC), which encompasses the advances that have been made over the years within the field of deep learning for human activity recognition and deep learning. Our work directly ties into the works of Bulling et al. and functions as a step-by-step framework to apply deep learning to any activity recognition use case. Within this tutorial, we will show how state-of-the-art models can be achieved, while along the way explaining all design choices in detail. This tutorial functions as a guide in the typical processes to design and evaluate deep learning architectures, once a human activity dataset has been recorded and annotated. We show through code snippets in a step-by-step process why certain steps are needed, how they affect the system’s outcome, and which pitfalls present themselves when designing a deep learning classifier. Participants do not need prior knowledge in human activity recognition or deep learning techniques, but should be familiar with programming in Python.

## Running the notebooks

### Google Colab
To work through the tutorial, we recommend you to use Google Colab. It offers an easy way for you to quickly run the code without needing to worry about your local setup. The links to each notebook are:

- Data Collection and Analysis
- Preprocessing
- Evaluation
- Training 
- Validation and Testing
- Next Research Steps

### Local deployment
