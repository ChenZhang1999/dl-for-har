{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preprocessing\n",
    "This notebook will teach you how to preprocess a sensor based Human Activity Recognition dataset.\n",
    "\n",
    "Let's readn-in the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "dataset = '/Users/ahoelzemann/Documents/git/dl-for-har/data/rwhar_3sbjs_data.csv'\n",
    "data = pd.read_csv(os.path.join(data_folder, dataset),\n",
    "                   names=['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity_label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Cleaning\n",
    "\n",
    "##### 1.1.1 Sensor Orientation\n",
    "\n",
    "Whenever we are working with a multimodal dataset, which means a dataset that consists of data from different sensors,\n",
    "we need to make sure that the sensor orientation of the data matches each other.\n",
    "\n",
    "\n",
    "\n",
    "Depending on the circumstances we want to clean the data before we train our classifier.\n",
    "\n",
    "It is very important to double check if the dataset contains **NaN - Values**. If the dataset contains these values\n",
    "make sure, that missing values are interpolated, since we want to keep the original sampling rate.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/html": "<img src=\"../images/pamap_skoda_orientation.png\"/>",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/pamap_skoda_orientation.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "interpolated_data = pd.concat([subject_id, acc_x, acc_y, acc_z, activity_label], axis=1)\n",
    "interpolated_data.columns = ['subject_id', 'acc_x', 'acc_y', 'acc_z', 'activity_label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Be careful with cleaning the data from noise or outlier, since it only is recommandable if the noise/outlier is not from any importance for the use case of our model.\n",
    "#### 1.2 Resampling\n",
    "\n",
    "Resampling is necessary if we work with sensor data from different sensors, that were not recorded with the sampling rate.\n",
    "The optimize the classifier we need to align the data sampling rates with each other.\n",
    "Resampling can either be done by up- or downsample the data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Normalizing\n",
    "Normalizing is in an important part in the preprocessing chain, but can also the reason for many mistakes.\n",
    "Therefore it is important to choose the correct strategy for normalizing your dataset.\n",
    "\n",
    "##### 1.3.1 How to normalize?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3 possible solutions to normalize correctly.\n",
    "Big pitfalls, since beginners tend to normalize the whole vector at once.\n",
    "\n",
    "Normalizing sensor-wise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.0193068 ],\n       [ 0.51856662],\n       [ 0.04323806],\n       ...,\n       [-0.05468475],\n       [ 0.51707086],\n       [ 0.01787214]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_sensorwise = MinMaxScaler(feature_range=[-1,1])\n",
    "\n",
    "scaled_sensorwise = scaler_sensorwise.fit_transform(interpolated_data[[\"acc_x\", \"acc_y\", \"acc_z\"]].values.reshape(-1,1))\n",
    "scaled_sensorwise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "before / after\n",
    "\n",
    "Normalizing axis-wise\n",
    "\n",
    "before / after\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler_axiswise = MinMaxScaler(feature_range=[-1,1])\n",
    "scaled_x = scaler_axiswise.fit_transform(interpolated_data[\"acc_x\"].values.reshape(-1,1))\n",
    "scaled_y = scaler_axiswise.fit_transform(interpolated_data[\"acc_y\"].values.reshape(-1,1))\n",
    "scaled_z = scaler_axiswise.fit_transform(interpolated_data[\"acc_z\"].values.reshape(-1,1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch-Normalization\n",
    "Where to put in the architecture?\n",
    "According to citation[] batch normalization layers should be placed after convolutional layers.\n",
    "\n",
    "\n",
    "#### 1.4 Windowing\n",
    "##### 1.4.1 Jumping/Sliding Window\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions\n",
    "\n",
    "Shuffling\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1f473f48",
   "language": "python",
   "display_name": "PyCharm (dl-for-har)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}